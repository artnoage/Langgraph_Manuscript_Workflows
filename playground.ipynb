{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from simple_workflows import *\n",
    "from simple_tools import *\n",
    "from workflows_as_tools import *\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receptionist: The following has been forwarded to the arxiv_retriever:  I'll create queries for each paper and send them to the retriever.\n",
      "\n",
      "Here's the first query:\n",
      "\n",
      "`\"An interpolating distance between optimal transport and Fisher-Rao metrics\"`\n",
      "\n",
      "Please wait for the response before I proceed to the next query.\n",
      "Retriever: I am going to call  get_id_from_url\n",
      "Tool_executor: I am going to executeget_id_from_urlwith{'url': 'https://export.arxiv.org/api/query?search_query=An_interpolating_distance_between_optimal_transport_and_Fisher-Rao_metrics&max_results=5'}\n",
      "Scraper: I got an error, going back to the arxiv_retriever\n",
      "Retriever:I am reporting back to the arxiv_receptionist withNo paper found for the query. Let's try with a different query.\n",
      "Reporting to receptionist\n",
      "Receptionist: The following has been forwarded to the arxiv_retriever:  Here's a revised query:\n",
      "\n",
      "`\"interpolating distance between optimal transport Fisher-Rao metrics\"`\n",
      "\n",
      "Please wait for the response.\n",
      "Retriever: I am going to call  get_id_from_url\n",
      "Tool_executor: I am going to executeget_id_from_urlwith{'url': 'https://export.arxiv.org/api/query?search_query=interpolating+distance+between+optimal+transport+Fisher-Rao+metrics&max_results=5'}\n",
      "Scraper: I got the following paperThe most relevant arXiv paper to the query is \"An Interpolating Distance between Optimal Transport and Fisher-Rao\" and its id-url is \"http://arxiv.org/abs/1506.06430v2\".\n",
      "Retriever: I am going to call  download_pdf\n",
      "Tool_executor: I am going to executedownload_pdfwith{'id': '1506.06430v2', 'title': 'Interpolating_Distance_Optimal_Transport'}\n",
      "Retriever:I am reporting back to the arxiv_receptionist withThe paper with the title 'An Interpolating Distance between Optimal Transport and Fisher-Rao' has successfully been downloaded.\n",
      "Reporting to receptionist\n",
      "Receptionist: The following has been forwarded to the arxiv_retriever:  Now, let's move on to the second query.\n",
      "\n",
      "Here's the query:\n",
      "\n",
      "`\"Unbalanced optimal transport Dynamic and Kantorovich formulations\"`\n",
      "\n",
      "Please wait for the response.\n",
      "Retriever: I am going to call  get_id_from_url\n",
      "Tool_executor: I am going to executeget_id_from_urlwith{'url': 'https://export.arxiv.org/api/query?search_query=Unbalanced+optimal+transport+Dynamic+and+Kantorovich+formulations&max_results=5'}\n",
      "Scraper: I got the following paperThe most relevant arXiv paper to the query is \"Unbalanced Optimal Transport: Dynamic and Kantorovich Formulation\" and its id-url is \"http://arxiv.org/abs/1508.05216v3\".\n",
      "Retriever: I am going to call  download_pdf\n",
      "Tool_executor: I am going to executedownload_pdfwith{'id': '1508.05216', 'title': 'Unbalanced_Optimal_Transport'}\n",
      "Retriever:I am reporting back to the arxiv_receptionist withThe paper with the title 'Unbalanced Optimal Transport: Dynamic and Kantorovich Formulation' has sucessfully been downloaded.\n",
      "Reporting to receptionist\n",
      "Receptionist**Final Report:**\n",
      "\n",
      "The following papers were successfully retrieved:\n",
      "\n",
      "1. 'An Interpolating Distance between Optimal Transport and Fisher-Rao'\n",
      "2. 'Unbalanced Optimal Transport: Dynamic and Kantorovich Formulation'\n",
      "\n",
      "We are done.\n",
      "**Final Report:**\n",
      "\n",
      "The following papers were successfully retrieved:\n",
      "\n",
      "1. 'An Interpolating Distance between Optimal Transport and Fisher-Rao'\n",
      "2. 'Unbalanced Optimal Transport: Dynamic and Kantorovich Formulation'\n",
      "\n",
      "We are done.\n"
     ]
    }
   ],
   "source": [
    "### This is a multiagent workflow. Its purpose is to retrieve a collection of papers from arxiv.\n",
    "### The input is a 'list' (in the sense of everyday speech) with each element being the name or keywords around the paper (check the bib file).\n",
    "### Under the hood it searches for the most relevant paper and downlads it in the pdf folder.\n",
    "### In the end you get a report of the papers that were retrieved.\n",
    "### This needs an OpenAI API key to work. There are ways around it, but you need to use a Chat method that uses tools. \n",
    "### You can try your own bibliography here. example bib={1. life of brian, 2. death rebearth 3.  time  illustion wondering face }\n",
    "\n",
    "input={\"receptionist_retriever_history\":[HumanMessage(content=\"\")],\n",
    "    \"last_action_outcome\":[HumanMessage(content=\"\")],\n",
    "    \"metadata\":HumanMessage(content=\" \"),\n",
    "    \"article_keywords\":HumanMessage(content=\" \"),\n",
    "    \"title_of_retrieved_paper\":HumanMessage(content=\" \"),\n",
    "    \"should_I_clean\": False}\n",
    "input[\"receptionist_retriever_history\"][0]=HumanMessage(content=\"Please fetch me the following papers:\" + \"1. An interpolating distance between optimal transport and Fisher-Rao metrics , 2 Unbalanced optimal transport: Dynamic and Kantorovich formulations_?\")\n",
    "\n",
    "### Here You can set different agents to staff the workflow. The default is arxiv_retriever_workflow(retrieval_model=ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0), \n",
    "### cleaner_model=ChatNVIDIA(model=\"meta/llama3-70b-instruct\"), receptionist_model=ChatNVIDIA(model=\"meta/llama3-70b-instruct\"))\n",
    "### the retrieval agents needs tools and ChatNVIDIA is still in development. \n",
    "\n",
    "retrieve_app=ArxivRetrievalWorkflow()\n",
    "retrieve_app=retrieve_app.create_workflow()\n",
    "retrieve_app=retrieve_app.compile()\n",
    "state=retrieve_app.invoke(input,{\"recursion_limit\": 100})    \n",
    "print(state[\"receptionist_retriever_history\"][-1].content)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "ArxivRetrievalTool=ArxivRetrievalToolClass()\n",
    "ArxivRetrievalTool=StructuredTool(name=\"ArxivRetrievalTool\",func=ArxivRetrievalTool.retrieve_bib,args_schema=ArxivRetrievalInput,\n",
    "                           description=ArxivRetrievalTool.description)\n",
    "ArxivRetrievalTool.invoke(\"1.Creatine for gains, 2. Is time relative or relativety had its time\")\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### It takes the name of a pdf located in the folder files\\pdfs as inpup and creates two markdowns, one with mupdf and one with nougat.\n",
    "pdf_to_markdown.invoke(\"Li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This tool takes two version of the same file and creates a new one that actually has the best of both worlds\n",
    "### As it is, it just fixes an issue with citation format with nougat by leveraging the ocr one gets from mupdf\n",
    "###(which is lower quality but with the right format). With a little bit of prompting tweeking it can get more\n",
    "### general tasks of this nature. This tool needs an embeding mechanism as well. The reason is to locate the pages\n",
    "### in the second file that correspond to the pages in the first.\n",
    "\n",
    "ocr_enhancer_app=OcrEnchancingWorkflow()\n",
    "ocr_enhancer_app=ocr_enhancer_app.create_workflow()\n",
    "ocr_enhancer_app=ocr_enhancer_app.compile()\n",
    "input={\"main_text_filename\": HumanMessage(content=\"Li\"), \"supporting_text_filename\": HumanMessage(content=\"mu_Li\")}\n",
    "state=ocr_enhancer_app.invoke(input)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "\n",
    "OcrEnhancingTool=OcrEnhancingToolClass()\n",
    "OcrEnhancingTool=StructuredTool(name=\"OcrEnhancingTool\",func=OcrEnhancingTool.ocr_enhance,args_schema=OcrEnhancingInput)\n",
    "OcrEnhancingTool.invoke({\"main_text_filename\": \"Li\", \"supporting_text_filename\": \"mu_Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The idea of this chain/tool is to remove the proofs from a paper so it will be easier to make a summary out of it. \n",
    "### The tool uses two chains under the hood. The first stamps the pages of the text that continue a proof from the previous page.\n",
    "### The idea was to help the LLM a bit to recognize proofs. The second LLM is doint the removal.\n",
    "### From all the modules I created, this was the most unsucessful one. Even with strong LLMs like GPT-4o and Opus, I had partial results.\n",
    "### I welcome anyone who can improve the prompt for this tool.\n",
    "proof_remover_app=ProofRemovingWorkflow()\n",
    "proof_remover_app=proof_remover_app.create_workflow()\n",
    "proof_remover_app=proof_remover_app.compile()\n",
    "input={\"main_text_filename\": HumanMessage(content=\"Li\"),\"file\":[\"\"],\"report\":HumanMessage(content=\"\")}\n",
    "state=proof_remover_app.invoke(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [02:44<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proofs were remove and the resulted file is named Li_without_proofs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The proofs were remove and the resulted file is named Li_without_proofs'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "\n",
    "ProofRemoverTool=ProofRemovalToolClass()\n",
    "ProofRemoverTool=StructuredTool(name=\"ProofRemovalTool\",func=ProofRemoverTool.remove_proof,args_schema=ProofRemovalInput)\n",
    "ProofRemoverTool.invoke({\"main_text_filename\": \"Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This tool takes a text found in the folder files/markdowns and creates a set of keywords and a summary. in a form of a string and extracts the keywords and summary.\n",
    "### It is preferable to use a file that doesnt contain proofs because it produces a better summary. \n",
    "input={\"main_text_filename\": HumanMessage(content=\"Li\"),\n",
    "           \"report\":HumanMessage(content=\"\"),}\n",
    "keyword_and_summary_app=KeywordAndSummaryWorkflow()\n",
    "keyword_and_summary_app=keyword_and_summary_app.create_workflow()\n",
    "keyword_and_summary_app=keyword_and_summary_app.compile()\n",
    "state=keyword_and_summary_app.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword_and_summary in progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 11/34 [01:33<03:50, 10.00s/it]"
     ]
    }
   ],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "\n",
    "KeywordAndSummaryTool=KeywordAndSummaryToolClass()\n",
    "KeywordAndSummaryTool=StructuredTool(name=\"KeywordAndSummaryTool\",func=KeywordAndSummaryTool.get_keyword_and_summary,args_schema=KeywordSummaryInput)\n",
    "KeywordAndSummaryTool.invoke({\"main_text_filename\": \"Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m translation_app\u001b[38;5;241m=\u001b[39mtranslation_app\u001b[38;5;241m.\u001b[39mcreate_workflow()\n\u001b[0;32m      9\u001b[0m translation_app\u001b[38;5;241m=\u001b[39mtranslation_app\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m---> 10\u001b[0m state\u001b[38;5;241m=\u001b[39m\u001b[43mtranslation_app\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(state)\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1448\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1447\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1448\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:983\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[0;32m    982\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 983\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1537\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(done, inflight, step)\u001b[0m\n\u001b[0;32m   1535\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m   1536\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[1;32m-> 1537\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m   1540\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[0;32m   1541\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[0;32m   1542\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\langgraph\\pregel\\retry.py:72\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     70\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2502\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2498\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m   2499\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2500\u001b[0m )\n\u001b[0;32m   2501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2502\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2504\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\langgraph\\utils.py:95\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m     94\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m---> 95\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\simple_workflows.py:288\u001b[0m, in \u001b[0;36mTranslationWorkflow.run_translator\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_translator\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m--> 288\u001b[0m     keywords_and_summary_filename \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeywords_and_summary_filename\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    289\u001b[0m     target_language \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_language\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    290\u001b[0m     main_text_filename \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_text_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "### This workflow trnaslates the text found in the folder files/markdowns/main_text_filename  to the target language.\n",
    "### it uses auxilary file for context based translation\n",
    "\n",
    "input={\"auxilary_text_filename\": HumanMessage(content=\"Li_keyword_and_summary\"), \"target_language\":HumanMessage(content=\"en\"),\"main_text_filename\": HumanMessage(content=\"Li\"), \"report\":HumanMessage}\n",
    "\n",
    "translation_app=TranslationWorkflow()\n",
    "translation_app=translation_app.create_workflow()\n",
    "translation_app=translation_app.compile()\n",
    "state=translation_app.invoke(input)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TranslationTool =TranslationToolClass()\n",
    "    \n",
    "TranslationTool=StructuredTool(name=\"TranslationTool\",func=TranslationTool.translate_file,args_schema=TranslatorInput,\n",
    "                           description=TranslationTool.description)\n",
    "TranslationTool.invoke(input={\"keywords_and_summary_filename\":\"\",\"target_language\":\"en\",\"main_text_filename\":\"Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This workflow takes a text found in the folder files/markdowns and creates a set of citations.\n",
    "### Extraction type should be provided (all of them/ most important)\n",
    "### An auxilary text can be provided which will help judge better if the extraction type matches.\n",
    "\n",
    "input={\"auxilary_text_filename\": HumanMessage(content=\"Li_keyword_and_summary\"), \"extraction_type\":HumanMessage(content=\"All of them\"),\"main_text_filename\": HumanMessage(content=\"Li\"), \n",
    "\"report\":HumanMessage(content=\"\")}\n",
    "\n",
    "citation_extraction_app=CitationExtractionWorkflow()\n",
    "citation_extraction_app=citation_extraction_app.create_workflow()\n",
    "citation_extraction_app=citation_extraction_app.compile()\n",
    "state=citation_extraction_app.invoke(input)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CitationExtractionTool=CitationExtractionToolClass()\n",
    "\n",
    "CitationExtractionTool=StructuredTool(name=\"CitationExtractionTool\",func=CitationExtractionTool.extract_citations,args_schema=CitationExtractorInput,\n",
    "                           description=CitationExtractionTool.description)  \n",
    "\n",
    "CitationExtractionTool.invoke(input={\"main_text_filename\":\"Li\",\"extraction_type\":\"All of them\",\"auxilary_text_filename\":\"Li_keyword_and_summary\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1189, which is longer than the specified 1000\n",
      "Created a chunk of size 1196, which is longer than the specified 1000\n",
      "Created a chunk of size 1890, which is longer than the specified 1000\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files\\temp\\Li_temp.mmd does not exist.\n",
      "{'main_text_filename': HumanMessage(content='Li'), 'report': \"The text was too long here is the inital part of the text:/n# Estimation optimale du gradient du semi-groupe de la chaleur sur le groupe de Heisenberg\\n\\nHong-Quan Li\\n\\n# Abstract\\n\\nSerB 611, Institut fur Angewandte Mathematik, Universitat Bonn, Poppelsdorfer Allee 82, D-53115 Bonn, Germany\\n\\nRequ le 6 juillet 2005 ; accepte le 21 fevrier 2006\\n\\nDisponible sur Internet le 18 avril 2006\\n\\nCommunique par G. Pisier\\n\\n## Resume\\n\\nEn utilisant l'inegalite de Poincare et la formule de representation, on montre que sur le groupe de Heisenberg de dimension reelle 3, \\\\(\\\\mathbb{H}^{1}\\\\), il existe une constante \\\\(C>0\\\\) telle que :\\n\\n\\\\[\\\\left|\\\\nabla e^{t\\\\,\\\\Delta}f\\\\right|(g)\\\\leqslant Ce^{t\\\\,\\\\Delta}\\\\big{(}|\\\\nabla f| \\\\big{)}(g),\\\\quad\\\\forall g\\\\in\\\\mathbb{H}^{1},\\\\ t>0,\\\\ f\\\\in C_{o}^{\\\\infty}\\\\big{(} \\\\mathbb{H}^{1}\\\\big{)}.\\\\]/n And here is the summary of the first three pages:With this new page, I can refine my understanding of the paper. Here's my updated list of keywords and summary:\\n\\n**Keywords:** Partial Differential Equations, Heat Equation, Semi-group, Heisenberg Group, Poincaré Inequality, Representation Formula, Gradient Estimation, Hypoelliptic heat kernel inequalities, Riemannian Manifolds, Ricci Curvature, Stochastic Completeness, Bakry's Estimate.\\n\\n**Summary:** The paper presents an optimal estimation of the gradient of the heat semi-group on the 3-dimensional Heisenberg group, using the Poincaré inequality and the representation formula, which answers an open question and generalizes a previous result on hypoelliptic heat kernel inequalities on the Heisenberg group. The paper also discusses the case of complete Riemannian manifolds with bounded Ricci curvature, where Bakry's estimate provides a way to bound the gradient of the heat semi-group.\\n\\nPlease provide the next page!\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### It skims a ttext and bring a very quick report. This will be only used as a tool for the manager, so it will not\n",
    "### request a tool usage that corresponds to a heavy workflow if this is not necceessary. It will take a peak on the file and get an idea.\n",
    "### Also useful for take citation files and sending them to the arxiv extractor.\n",
    "input={\"main_text_filename\": HumanMessage(content=\"Li\"),\"report\":HumanMessage(content=\"\")}\n",
    "take_a_peak_app=TakeAPeakWorkflow()\n",
    "take_a_peak_app=take_a_peak_app.create_workflow()\n",
    "take_a_peak_app=take_a_peak_app.compile()\n",
    "state=take_a_peak_app.invoke(input)\n",
    "print(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaios",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
